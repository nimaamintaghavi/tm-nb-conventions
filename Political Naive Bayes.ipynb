{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import re, itertools\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenCleaner():\n",
    "    def __init__(self, remove_stopwords=True, return_as_string=True):\n",
    "        \n",
    "        # Some punctuation variations\n",
    "        self.punctuation = set(punctuation) # speeds up comparison\n",
    "        self.punct_set = self.punctuation - {\"#\"}\n",
    "        self.punct_pattern = \\\n",
    "            re.compile(\"[\" + re.escape(\"\".join(self.punct_set)) + \"]\")\n",
    "\n",
    "        # Stopwords\n",
    "        if remove_stopwords:\n",
    "            self.sw = stopwords.words(\"english\") + ['️','',' ']\n",
    "        else:\n",
    "            self.sw = ''\n",
    "            \n",
    "        # Two useful regex\n",
    "        self.whitespace_pattern = re.compile(r\"\\s+\")\n",
    "        self.hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "        \n",
    "        self.CleanText_return_format = return_as_string\n",
    "\n",
    "    def CleanText(self, _text):\n",
    "\n",
    "        # decode bytes to string if necessary\n",
    "        if isinstance(_text, str): \n",
    "            self.text = _text\n",
    "        else:\n",
    "            # this is for the case of tweets which are saved as bytes\n",
    "            self.text = _text.decode(\"utf-8\") \n",
    "      \n",
    "        self.__RemovePunctuation()\n",
    "        self.__TokenizeText()\n",
    "        self.__RemoveStopWords()\n",
    "        if self.CleanText_return_format:\n",
    "            return ' '.join(self.tokens)\n",
    "        else:\n",
    "            return self.tokens\n",
    "        \n",
    "    def __RemovePunctuation(self): \n",
    "        \"\"\"\n",
    "        Loop through the original text and check each character,\n",
    "        if the character is a punctuation, then it is removed.\n",
    "        ---------------------------------------------------------\n",
    "        input: original text\n",
    "        output: text without punctuation\n",
    "        \"\"\"\n",
    "        self.text = \\\n",
    "            \"\".join([ch for ch in self.text if ch not in self.punct_set])\n",
    "            \n",
    "        self.text = re.sub(self.punct_pattern, '', self.text)\n",
    "        \n",
    "    def __TokenizeText(self):\n",
    "        \"\"\"\n",
    "        Tokenize by splitting the text by white space\n",
    "        ---------------------------------------------------------\n",
    "        input: text without punctuation\n",
    "        output: A list of tokens\n",
    "        \"\"\"\n",
    "        self.tokens = \\\n",
    "            [item for item in self.whitespace_pattern.split(self.text)]\n",
    "                \n",
    "    def __RemoveStopWords(self): \n",
    "        \"\"\"\n",
    "        Tokenize by splitting the text by white space\n",
    "        ---------------------------------------------------------\n",
    "        input: text without punctuation\n",
    "        output: A list of tokens with all token as lower case\n",
    "        \"\"\"\n",
    "        self.tokens = [token.lower() for token in self.tokens]\n",
    "        \n",
    "        self.tokens = \\\n",
    "            [token for token in self.tokens if not token in self.sw]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>voted campaigned republicans since reagan year...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>could use little help right seems like get one...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>utah</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>got back yeah</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>thank kristin sharing story nation grieves fat...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>lived feeling helplessness someone love sick a...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>welcome</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>official roll call business republican convent...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>together ivanka wrote policies made easier sta...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>good evening presidential election world’s imp...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text       party\n",
       "2166  voted campaigned republicans since reagan year...  Democratic\n",
       "2413  could use little help right seems like get one...  Democratic\n",
       "512                                                utah  Republican\n",
       "681                                       got back yeah  Republican\n",
       "2004  thank kristin sharing story nation grieves fat...  Democratic\n",
       "1525  lived feeling helplessness someone love sick a...  Democratic\n",
       "1488                                            welcome  Democratic\n",
       "462   official roll call business republican convent...  Republican\n",
       "1261  together ivanka wrote policies made easier sta...  Republican\n",
       "1607  good evening presidential election world’s imp...  Democratic"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_data = list()\n",
    "\n",
    "# fill this list up with items that are themselves lists. \n",
    "# The first element in the sublist should be the cleaned \n",
    "# and tokenized text in a single string. \n",
    "# The second element should be the party. \n",
    "\n",
    "sql_query = \"SELECT party, text FROM conventions\"\n",
    "query_results = convention_cur.execute(sql_query)\n",
    "\n",
    "# create an instance of the TokenCleaner class \n",
    "# which will be used to clean the text\n",
    "\n",
    "# Some configuration that can be set are:\n",
    "# -> removing stop words or not \n",
    "# -> returning as a list of tokens or as one string\n",
    "\n",
    "tc = TokenCleaner(remove_stopwords=True, return_as_string=True)\n",
    "for party, text in query_results:\n",
    "    # clean the text and tokenize\n",
    "    tokens = tc.CleanText(text)\n",
    "    convention_data.append([tokens, party])    \n",
    "\n",
    "\n",
    "# show sample of the text and their party \n",
    "df = pd.DataFrame(convention_data, columns =[['text', 'party']])\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['jon honor devotion showing returning citizens forgotten believe person made god purpose continue give americans including former inmates best chance build new life achieve american dream great american dream i’d like ask john richard say words',\n",
       "  'Republican'],\n",
       " ['navy senate liaison used carry bags overseas trips', 'Democratic'],\n",
       " ['support defend', 'Republican'],\n",
       " ['son scranton claymont wilmington become one consequential vice presidents american history accolade nonetheless rest firmly behind legacy husband father grandfather grateful nation thanks vice president joseph r biden jr lifetime service behalf united states america',\n",
       "  'Democratic'],\n",
       " ['care environment', 'Democratic'],\n",
       " ['next', 'Democratic'],\n",
       " ['jordan president trump standing right would say today right try',\n",
       "  'Republican'],\n",
       " ['president trump recognized one small ways instill sense normalcy people’s lives bring back entertainment options president went beyond help sports leagues involved figure way overcome challenges staging live professional sporting events middle pandemic know ufc first continuing',\n",
       "  'Republican'],\n",
       " ['proud joe’s team joe team', 'Democratic'],\n",
       " ['it’s one great american success stories builder left mark skylines around world businessman extraordinary ability communicate directly american people leader grew tired politicians leading country road ruin didn’t money power fame love great country',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_words(dataset, word_cutoff = 5, print_accuracy = False):\n",
    "\n",
    "    tokens = [w for t, p in dataset for w in t.split()]\n",
    "    word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "    feature_words = set()\n",
    "\n",
    "    for word, count in word_dist.items() :\n",
    "        if count > word_cutoff :\n",
    "            feature_words.add(word)\n",
    "    if print_accuracy:       \n",
    "        print(f\"With a word cutff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")\n",
    "    \n",
    "    return feature_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "    \"\"\"\n",
    "    \n",
    "    ret_dict = {token:True for token in text.split(' ') if token in fw}\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutff of 5, we have 2391 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "feature_words_convention = get_feature_words(convention_data, print_accuracy = True)\n",
    "\n",
    "assert(len(feature_words_convention)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words_convention)==\n",
    "       {'donald':True,'president':True})\n",
    "\n",
    "assert(conv_features(\"people are american in america\",feature_words_convention)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets_conv = [(conv_features(text,feature_words_convention), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets_conv)\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets_conv[:test_size], featuresets_conv[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "_Your observations to come._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "tweet_results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303219</th>\n",
       "      <td>50 years ago #shirleychisholm became first afr...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581429</th>\n",
       "      <td>#teammcclure great weekend getting talk voters...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32428</th>\n",
       "      <td>today remember victims 911 terrorist attacks p...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361606</th>\n",
       "      <td>mental health awareness month must recommit in...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100069</th>\n",
       "      <td>thoughts prayers mccain family history remembe...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124416</th>\n",
       "      <td>dont forget send best original pictures cas 14...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437373</th>\n",
       "      <td>70 years ago today president truman recognized...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257613</th>\n",
       "      <td>happy st patricks day</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283299</th>\n",
       "      <td>two weeks election day #voteready</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61638</th>\n",
       "      <td>insurance companies ralphnorman amp tommypopes...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       party\n",
       "303219  50 years ago #shirleychisholm became first afr...  Democratic\n",
       "581429  #teammcclure great weekend getting talk voters...  Democratic\n",
       "32428   today remember victims 911 terrorist attacks p...  Republican\n",
       "361606  mental health awareness month must recommit in...  Democratic\n",
       "100069  thoughts prayers mccain family history remembe...  Republican\n",
       "124416  dont forget send best original pictures cas 14...  Democratic\n",
       "437373  70 years ago today president truman recognized...  Republican\n",
       "257613                              happy st patricks day  Democratic\n",
       "283299                  two weeks election day #voteready  Democratic\n",
       "61638   insurance companies ralphnorman amp tommypopes...  Democratic"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "tweet_data = []\n",
    "for candidate, party, text in tweet_results:\n",
    "    tokens = tc.CleanText(text)\n",
    "    tweet_data.append([tokens, party])    \n",
    "    \n",
    "df_tweet = pd.DataFrame(tweet_data, columns =[['text', 'party']])\n",
    "df_tweet.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv',\n",
       "  'Democratic'],\n",
       " ['go tribe #rallytogether httpstco0nxutfl9l5', 'Democratic'],\n",
       " ['apparently trump thinks easy students overwhelmed crushing burden debt pay student loans #trumpbudget httpstcockyqo5t0qh',\n",
       "  'Democratic'],\n",
       " ['we’re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3',\n",
       "  'Republican'],\n",
       " ['let’s make even greater #kag 🇺🇸 httpstcoy9qozd5l2z', 'Republican'],\n",
       " ['1hr cavs tie series 22 im #allin216 repbarbaralee scared #roadtovictory',\n",
       "  'Democratic'],\n",
       " ['congrats belliottsd new gig sd city hall glad continue serve… httpstcofkvmw3cqdi',\n",
       "  'Democratic'],\n",
       " ['really close 3500 raised toward match right whoot that’s 7000 nonmath majors room 😂 help us get httpstcotu34c472sd httpstcoqsdqkypsmc',\n",
       "  'Democratic'],\n",
       " ['today comment period potus’s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn',\n",
       "  'Democratic'],\n",
       " ['celebrated icseastla’s 22 years eastside commitment amp saluted community leaders last night’s awards dinner httpstco7v7gh8givb',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(20201014)\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)\n",
    "tweet_data_sample   \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe #rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans #trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: we’re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: let’s make even greater #kag 🇺🇸 httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: 1hr cavs tie series 22 im #allin216 repbarbaralee scared #roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serve… httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot that’s 7000 nonmath majors room 😂 help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potus’s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastla’s 22 years eastside commitment amp saluted community leaders last night’s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    tokens = conv_features(tweet,feature_words_convention)\n",
    "    estimated_party = classifier.classify(tokens)\n",
    "       \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "# Loop through tweets and predict whether the person tweeting is a Republican or a Democratic \n",
    "# based on tokens from convention_data\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "\n",
    "    tokens = conv_features(tweet,feature_words_convention)\n",
    "    estimated_party = classifier.classify(tokens)   \n",
    "     \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate for Democratic Party: 60.87% \n",
      "\n",
      "\n",
      "{'Democratic': defaultdict(<class 'int'>,\n",
      "                           {'Democratic': 907,\n",
      "                            'Republican': 4817}),\n",
      " 'Republican': defaultdict(<class 'int'>,\n",
      "                           {'Democratic': 583,\n",
      "                            'Republican': 3695})}\n"
     ]
    }
   ],
   "source": [
    "# Get the proportion of the times which Democratic were predicted correctly by the model\n",
    "TP_Democratic = results['Democratic']['Democratic'] / (results['Republican']['Democratic'] + results['Democratic']['Democratic'])\n",
    "\n",
    "print(f'True Positive Rate for Democratic Party: {TP_Democratic:0.2%}','\\n\\n')\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(dict(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "It is apparent that most of the estimates are the model makes is Republican. Since there is 50% chance of guessing, the model does just a little bit better which is about 61%. There are some elements that can improve the model such as using the features that return False, optimizing word_cutoffs, split of train and test, etc.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
